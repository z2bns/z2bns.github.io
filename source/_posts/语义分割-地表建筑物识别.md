---
title: è¯­ä¹‰åˆ†å‰²-åœ°è¡¨å»ºç­‘ç‰©è¯†åˆ«
date: 2021-03-12 16:28:36
mathjax: true
categories:
- æœºå™¨å­¦ä¹ 
tags:
- å¤©æ± 
- è®¡ç®—æœºè§†è§‰
---

[å¤©æ± æ¯”èµ›åœ°å€](https://tianchi.aliyun.com/competition/entrance/531872/information)

| æ–‡æ¡£                  | æ ¼å¼      |
| --------------------- | --------- |
| SS_Data_A_20210201.md | .md(939B) |

<!-- more -->

##### èµ›é¢˜èƒŒæ™¯

èµ›é¢˜ä»¥è®¡ç®—æœºè§†è§‰ä¸ºèƒŒæ™¯ï¼Œè¦æ±‚é€‰æ‰‹ä½¿ç”¨ç»™å®šçš„èˆªæ‹å›¾åƒè®­ç»ƒæ¨¡å‹å¹¶å®Œæˆåœ°è¡¨å»ºç­‘ç‰©è¯†åˆ«ä»»åŠ¡ã€‚ä¸ºæ›´å¥½çš„å¼•å¯¼å¤§å®¶å…¥é—¨ï¼Œæˆ‘ä»¬ä¸ºæœ¬èµ›é¢˜å®šåˆ¶äº†å­¦ä¹ æ–¹æ¡ˆå’Œå­¦ä¹ ä»»åŠ¡ï¼Œå…·ä½“åŒ…æ‹¬è¯­ä¹‰åˆ†å‰²çš„æ¨¡å‹å’Œå…·ä½“çš„åº”ç”¨æ¡ˆä¾‹ã€‚åœ¨å…·ä½“ä»»åŠ¡ä¸­æˆ‘ä»¬å°†è®²è§£å…·ä½“å·¥å…·å’Œä½¿ç”¨å’Œå®Œæˆä»»åŠ¡çš„è¿‡ç¨‹ã€‚

é€šè¿‡å¯¹æœ¬æ–¹æ¡ˆçš„å®Œæ•´å­¦ä¹ ï¼Œå¯ä»¥å¸®åŠ©æŒæ¡è¯­ä¹‰åˆ†å‰²åŸºæœ¬æŠ€èƒ½ã€‚åŒæ—¶æˆ‘ä»¬ä¹Ÿå°†æä¾›ä¸“å±çš„è§†é¢‘ç›´æ’­å­¦ä¹ é€šé“ã€‚

##### èµ›é¢˜æè¿°åŠæ•°æ®è¯´æ˜

é¥æ„ŸæŠ€æœ¯å·²æˆä¸ºè·å–åœ°è¡¨è¦†ç›–ä¿¡æ¯æœ€ä¸ºè¡Œä¹‹æœ‰æ•ˆçš„æ‰‹æ®µï¼Œé¥æ„ŸæŠ€æœ¯å·²ç»æˆåŠŸåº”ç”¨äºåœ°è¡¨è¦†ç›–æ£€æµ‹ã€æ¤è¢«é¢ç§¯æ£€æµ‹å’Œå»ºç­‘ç‰©æ£€æµ‹ä»»åŠ¡ã€‚æœ¬èµ›é¢˜ä½¿ç”¨èˆªæ‹æ•°æ®ï¼Œéœ€è¦å‚èµ›é€‰æ‰‹å®Œæˆåœ°è¡¨å»ºç­‘ç‰©è¯†åˆ«ï¼Œå°†åœ°è¡¨èˆªæ‹å›¾åƒç´ åˆ’åˆ†ä¸ºæœ‰å»ºç­‘ç‰©å’Œæ— å»ºç­‘ç‰©ä¸¤ç±»ã€‚

å¦‚ä¸‹å›¾ï¼Œå·¦è¾¹ä¸ºåŸå§‹èˆªæ‹å›¾ï¼Œå³è¾¹ä¸ºå¯¹åº”çš„å»ºç­‘ç‰©æ ‡æ³¨ã€‚

![enter image description here](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-%E5%9C%B0%E8%A1%A8%E5%BB%BA%E7%AD%91%E7%89%A9%E8%AF%86%E5%88%AB/161218137939445491612181378279.png)

èµ›é¢˜æ•°æ®æ¥æºï¼ˆInria Aerial Image Labelingï¼‰ï¼Œå¹¶è¿›è¡Œæ‹†åˆ†å¤„ç†ã€‚æ•°æ®é›†æŠ¥ååå¯è§å¹¶å¯ä¸‹è½½ã€‚èµ›é¢˜æ•°æ®ä¸ºèˆªæ‹å›¾ï¼Œéœ€è¦å‚èµ›é€‰æ‰‹è¯†åˆ«å›¾ç‰‡ä¸­çš„åœ°è¡¨å»ºç­‘å…·ä½“åƒç´ ä½ç½®ã€‚

- `train_mask.csv`ï¼šå­˜å‚¨å›¾ç‰‡çš„æ ‡æ³¨çš„rleç¼–ç ï¼›
- `train`å’Œ`test`æ–‡ä»¶å¤¹ï¼šå­˜å‚¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†å›¾ç‰‡ï¼›

rleç¼–ç çš„å…·ä½“çš„è¯»å–ä»£ç å¦‚ä¸‹(æ·»åŠ äº†æ³¨é‡Š)ï¼š

```python
import numpy as np
'''
NumPy(Numerical Python) æ˜¯ Python è¯­è¨€çš„ä¸€ä¸ªæ‰©å±•ç¨‹åºåº“ï¼ˆå¼€æºï¼‰ï¼Œæ”¯æŒå¤§é‡çš„ç»´åº¦æ•°ç»„ä¸çŸ©é˜µè¿ç®—ï¼Œæ­¤å¤–ä¹Ÿé’ˆå¯¹æ•°ç»„è¿ç®—æä¾›å¤§é‡çš„æ•°å­¦å‡½æ•°åº“ã€‚
'''
import pandas as pd
'''
pandas æ˜¯åŸºäºNumPy çš„ä¸€ç§å·¥å…·ï¼Œè¯¥å·¥å…·æ˜¯ä¸ºè§£å†³æ•°æ®åˆ†æä»»åŠ¡è€Œåˆ›å»ºçš„ã€‚Pandas çº³å…¥äº†å¤§é‡åº“å’Œä¸€äº›æ ‡å‡†çš„æ•°æ®æ¨¡å‹ï¼Œæä¾›äº†é«˜æ•ˆåœ°æ“ä½œå¤§å‹æ•°æ®é›†æ‰€éœ€çš„å·¥å…·
'''
import cv2
'''
CV2æŒ‡çš„æ˜¯OpenCV2ï¼ŒOpenCVæ˜¯ä¸€ä¸ªåŸºäºBSDè®¸å¯ï¼ˆå¼€æºï¼‰å‘è¡Œçš„è·¨å¹³å°è®¡ç®—æœºè§†è§‰åº“
'''

# å°†å›¾ç‰‡ç¼–ç ä¸ºrleæ ¼å¼
def rle_encode(im):
    '''
    im: numpy array, 1 - mask, 0 - background
    Returns run length as string formated
    '''
    pixels = im.flatten(order = 'F')
    #flattenå‡½æ•°ï¼šå¯é€‰orderå‚æ•°ï¼Œâ€˜C'(flatten in row-major)ï¼Œâ€™Fâ€˜(flatten in column-major)ï¼Œâ€™Aâ€˜ï¼Œâ€™Kâ€˜,è¿”å›flattenåçš„ä¸€ç»´æ•°ç»„
    pixels = np.concatenate([[0], pixels, [0]])
   	#np.concatenate()æ˜¯ç”¨æ¥å¯¹æ•°åˆ—æˆ–çŸ©é˜µè¿›è¡Œåˆå¹¶çš„ï¼ŒæŠŠä¸€ç»´æ•°ç»„é¦–ä½å„åŠ ä¸€ä¸ª0
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    #np.where():ä»¥tupleå½¢å¼ç»™å‡ºæ»¡è¶³æ¡ä»¶(å³é0)çš„å…ƒç´ çš„åæ ‡
    #è¿™é‡Œrunsæ•°ç»„å†…å®¹ä¸ºpixelsä¸­ä¸å‰ä¸€ä¸ªæ•°ä¸ç­‰çš„å…ƒç´ çš„ä½ç½®
    runs[1::2] -= runs[::2]
    #æ›´æ”¹runsä¸­ä»ç¬¬ä¸€ä¸ªä½ç½®å¼€å§‹é—´éš”ä¸º2è¿™äº›å…ƒç´ çš„å€¼ä¸ºä¸å‰ä¸€ä¸ªå…ƒç´ å€¼çš„å·®
    return ' '.join(str(x) for x in runs)
	#è¿”å›ç”¨é—´éš”åˆ†å‰²çš„runsæ•°ç»„å…ƒç´ çš„å­—ç¬¦ä¸²

# å°†rleæ ¼å¼è¿›è¡Œè§£ç ä¸ºå›¾ç‰‡
def rle_decode(mask_rle, shape=(512, 512)):
    '''
    mask_rle: run-length as string formated (start length)
    shape: (height,width) of array to return 
    Returns numpy array, 1 - mask, 0 - background

    '''
    s = mask_rle.split()
    '''
    str.split(str="", num=string.count(str)):é€šè¿‡æŒ‡å®šåˆ†éš”ç¬¦å¯¹å­—ç¬¦ä¸²è¿›è¡Œåˆ‡ç‰‡ï¼Œå¦‚æœå‚æ•° num æœ‰æŒ‡å®šå€¼ï¼Œåˆ™åˆ†éš” num+1 ä¸ªå­å­—ç¬¦ä¸²
    paramå‚æ•°
    str--é»˜è®¤ä¸ºæ‰€æœ‰çš„ç©ºå­—ç¬¦ï¼ˆç©ºæ ¼ã€æ¢è¡Œã€åˆ¶è¡¨ç¬¦ç­‰ï¼‰
    num--åˆ†å‰²æ¬¡æ•°ï¼Œé»˜è®¤ä¸º-1ï¼Œåˆ†å‰²æ‰€æœ‰
    return--è¿”å›åˆ†å‰²åçš„å­—ç¬¦ä¸²åˆ—è¡¨
    '''
    
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    '''
    arrayå’Œasarrayéƒ½å¯ä»¥å°†ç»“æ„æ•°æ®è½¬åŒ–ä¸ºndarrayï¼Œä½†æ˜¯ä¸»è¦åŒºåˆ«å°±æ˜¯å½“æ•°æ®æºæ˜¯ndarrayæ—¶ï¼Œarrayä»ç„¶ä¼šcopyå‡ºä¸€ä¸ªå‰¯æœ¬ï¼Œå ç”¨æ–°çš„å†…å­˜ï¼Œä½†asarrayä¸ä¼š
    startsä¸ºåˆ—è¡¨sä¸­å¶æ•°ä½ç½®å…ƒç´ ç»„æˆçš„æ•°ç»„ï¼Œlengthsä¸ºåˆ—è¡¨sä¸­å¥‡æ•°ä½ç½®å…ƒç´ ç»„æˆçš„æ•°ç»„
    '''
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    #uint8æ˜¯ä¸“é—¨ç”¨äºå­˜å‚¨å„ç§å›¾åƒçš„ï¼ˆåŒ…æ‹¬RGBï¼Œç°åº¦å›¾åƒç­‰ï¼‰ï¼ŒèŒƒå›´æ˜¯ä»0â€“255
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape, order='F')
	#reshape():åœ¨ä¸æ”¹å˜æ•°æ®å†…å®¹çš„æƒ…å†µä¸‹ï¼Œæ”¹å˜ä¸€ä¸ªæ•°ç»„çš„æ ¼å¼
```

è¯»å–æ ·ä¾‹ï¼š

```python
train_mask = pd.read_csv('train_mask.csv', sep='\t', names=['name', 'mask'])
'''
pandas.read_csv(filepath_or_buffer,sep,header,names)
filepath_or_buffer--å­—ç¬¦ä¸²ï¼Œæ–‡ä»¶è·¯å¾„å
sep--æŒ‡å®šåˆ†éš”ç¬¦ï¼Œé»˜è®¤æ˜¯é€—å·
header--æŒ‡å®šè¡Œæ•°ä½œä¸ºåˆ—åï¼Œé»˜è®¤ä¸º0ï¼Œå¦åˆ™è®¾ç½®ä¸ºNone
names--ç”¨äºç»“æœçš„åˆ—ååˆ—è¡¨
'''
# è¯»å–ç¬¬ä¸€å¼ å›¾ï¼Œå¹¶å°†å¯¹äºçš„rleè§£ç ä¸ºmaskçŸ©é˜µ
img = cv2.imread('train/'+ train_mask['name'].iloc[0])
'''
cv2.imread(filepath,flags)è¯»å…¥ä¸€å¹…å›¾ç‰‡
filepath--å›¾ç‰‡è·¯å¾„
flags--è¯»å…¥å›¾ç‰‡çš„å½¢å¼é»˜è®¤æ˜¯è¯»å–å½©è‰²å›¾ç‰‡
ilocæå–æŒ‡å®šä½ç½®çš„å…ƒç´ ï¼Œè¿™é‡Œæ˜¯å–å‡ºnameåˆ—çš„ç¬¬ä¸€è¡Œæ•°æ®ï¼Œå³ç¬¬ä¸€å¼ å›¾ç‰‡çš„åç§°
'''
mask = rle_decode(train_mask['mask'].iloc[0])

print(rle_encode(mask) == train_mask['mask'].iloc[0])
# ç»“æœä¸ºTrue
```

##### è¯„ä¼°æ ‡å‡†

èµ›é¢˜ä½¿ç”¨Dice coefficientæ¥è¡¡é‡é€‰æ‰‹ç»“æœä¸çœŸå®æ ‡ç­¾çš„å·®å¼‚æ€§ï¼ŒDice coefficientå¯ä»¥æŒ‰åƒç´ å·®å¼‚æ€§æ¥æ¯”è¾ƒç»“æœçš„å·®å¼‚æ€§ã€‚Dice coefficientçš„å…·ä½“è®¡ç®—æ–¹å¼å¦‚ä¸‹ï¼š
$$
\frac{2 * |X \cap Y|}{|X| + |Y|}âˆ£*X*âˆ£+âˆ£*Y*âˆ£2âˆ—âˆ£*X*âˆ©*Y*âˆ£
$$
å…¶ä¸­X*X*æ˜¯é¢„æµ‹ç»“æœï¼ŒY*Y*ä¸ºçœŸå®æ ‡ç­¾çš„ç»“æœã€‚å½“X*X*ä¸Y*Y*å®Œå…¨ç›¸åŒæ—¶Dice coefficientä¸º1ï¼Œæ’è¡Œæ¦œä½¿ç”¨æ‰€æœ‰æµ‹è¯•é›†å›¾ç‰‡çš„å¹³å‡Dice coefficientæ¥è¡¡é‡ï¼Œåˆ†æ•°å€¼è¶Šå¤§è¶Šå¥½ã€‚

##### ç»“æœæäº¤

æäº¤å‰è¯·ç¡®ä¿é¢„æµ‹ç»“æœçš„æ ¼å¼ä¸`test_sample_submit.csv`ä¸­çš„æ ¼å¼ä¸€è‡´ï¼Œä»¥åŠæäº¤æ–‡ä»¶åç¼€åä¸ºcsvã€‚

æ³¨æ„äº‹é¡¹ï¼š

- ç¬¬ä¸€åˆ—ä¸ºtestå›¾ç‰‡åç§°ï¼Œç¬¬äºŒåˆ—ä¸ºrleç¼–ç ï¼›
- å¦‚æµ‹è¯•é›†å›¾æ²¡æœ‰è¯†åˆ«å‡ºç»“æœï¼Œä¹Ÿéœ€è¦æäº¤ç©ºå­—ç¬¦ä¸²ï¼›
- æµ‹è¯•é›†å›¾ç‰‡é¡ºåºéœ€è¦ä¸`test_sample_submit.csv`ä¿æŒä¸€è‡´ï¼›

##### æ¯”èµ›è§„åˆ™

1. ä¸ºäº†æ¯”èµ›å…¬å¹³å…¬æ­£ï¼Œæ‰€æœ‰å‚èµ›é€‰æ‰‹**ä¸å…è®¸ä½¿ç”¨ä»»ä½•å¤–éƒ¨æ•°æ®é›†**ï¼ˆå¦‚å¤–éƒ¨èˆªæ‹æ•°æ®ï¼‰ã€‚åŒæ—¶æ‰€æœ‰å‚èµ›é€‰æ‰‹**ä¸å…è®¸ä½¿ç”¨ä»»ä½•éå…¬å¼€çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå…¬å¼€çš„é¢„è®­ç»ƒæ¨¡å‹**ï¼ˆå¦‚ImageNetå’ŒCOCOï¼‰å¯ä»¥ä½¿ç”¨ã€‚
2. ä¸ºäº†æ¯”èµ›è¶£å‘³æ€§ï¼Œä¸å»ºè®®é€‰æ‰‹ä½¿ç”¨ä¼ªæ ‡ç­¾æ“ä½œï¼ŒåŒæ—¶å»ºè®®é€‰æ‰‹ä¿å­˜å¥½ä»£ç ï¼Œæœ€ç»ˆæ¯”èµ›ç¨‹åºä»£ç éœ€è¦å®Œæ•´å¤ç°ã€‚

##### è§£é¢˜æ€è·¯

æœ¬æ¥ä»¥ä¸ºå¯ä»¥ä¸ç”¨è®­ç»ƒï¼Œç›´æ¥ç”¨å›¾åƒäºŒå€¼åŒ–æ–¹æ³•å¤„ç†å°±èƒ½å¾—åˆ°å›¾åƒäºŒå€¼åŒ–æ•°æ®ï¼Œæµ‹è¯•è®­ç»ƒé›†ä¸€å¼ å›¾ç‰‡å‡ºç°å¤±è¯¯è§‰å¾—è¿™ç§æ–¹æ³•å¯è¡Œï¼Œæœ€åå¤„ç†å®Œæµ‹è¯•é›†æ‰å‘ç°å¾—åˆ°çš„rleç¼–ç å¤ªé•¿ï¼ˆåŒ…å«å¤ªå¤šçš„ç»†èŠ‚ï¼‰å¯¼è‡´æµ‹è¯•é›†ç»“æœæ–‡ä»¶å¤ªå¤§238Mè€Œé¢˜ç›®è¦æ±‚50Mä»¥å†…ï¼Œæ•…å¿…é¡»å»ºç«‹æ¨¡å‹è¿›è¡Œè®­ç»ƒäº†ğŸ¤£ï¼Œè¿˜ä»¥ä¸ºèƒ½èµ°æ·å¾„å‘¢ï¼Œå“ˆå“ˆå“ˆã€‚

![image-20210309215312755](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-%E5%9C%B0%E8%A1%A8%E5%BB%BA%E7%AD%91%E7%89%A9%E8%AF%86%E5%88%AB/image-20210309215312755.png)



æ ¹æ®é¢˜ç›®æç¤ºï¼Œæ˜¯è¦ä½¿ç”¨DiceLossæŸå¤±å‡½æ•°ï¼Œä½†é—®é¢˜æ˜¯æ€ä¹ˆæ„å»ºæ¨¡å‹èƒ½å¯¹å›¾ç‰‡è¾“å‡ºé¢„æµ‹å€¼ï¼ˆ0-1äºŒå€¼åŒ–ï¼‰å‘¢

ï¼Œå°è¯•äº†å¾ˆä¹…æœªæœï¼Œæ— å¥ˆæ±‚åŠ©ç½‘ç»œï¼Œæ‰¾åˆ°äº†æœ‰å¤§ä½¬åˆ†äº«çš„baselineä»£ç ï¼Œè·‘æ¨¡å‹å¦‚ä¸‹



å›¾ç‰‡rleè§£ç ç¼–ç æµ‹è¯•

![image-20210309100134328](file://F:\è¯¾é¢˜é¡¹ç›®\å¤©æ± \é›¶åŸºç¡€å…¥é—¨è¯­ä¹‰åˆ†å‰²-åœ°è¡¨å»ºç­‘ç‰©è¯†åˆ«\notes\image-20210309100134328.png?lastModify=1615538546)



```c++
import numpy as np
import pandas as pd
import pathlib, sys, os, random, time
import numba, cv2, gc
from tqdm import tqdm_notebook

import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

from tqdm.notebook import tqdm
# albumentations æ˜¯ä¸€ä¸ªç»™äºˆ OpenCVçš„å¿«é€Ÿè®­ç»ƒæ•°æ®å¢å¼ºåº“,æ‹¥æœ‰éå¸¸ç®€å•ä¸”å¼ºå¤§çš„å¯ä»¥ç”¨äºå¤šç§ä»»åŠ¡(åˆ†å‰²ã€æ£€æµ‹)çš„æ¥å£,æ˜“äºå®šåˆ¶ä¸”æ·»åŠ å…¶ä»–æ¡†æ¶éå¸¸æ–¹ä¾¿
import albumentations as A
#Rasterioæ˜¯åŸºäºGDALåº“äºŒæ¬¡å°è£…çš„æ›´åŠ ç¬¦åˆPythoné£æ ¼çš„ä¸»è¦ç”¨äºç©ºé—´æ …æ ¼æ•°æ®å¤„ç†çš„Pythonåº“
import rasterio
from rasterio.windows import Window

def rle_encode(im):
    '''
    im: numpy array, 1 - mask, 0 - background
    Returns run length as string formated
    '''
    pixels = im.flatten(order = 'F')
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)

def rle_decode(mask_rle, shape=(512, 512)):
    '''
    mask_rle: run-length as string formated (start length)
    shape: (height,width) of array to return 
    Returns numpy array, 1 - mask, 0 - background

    '''
    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape, order='F')




import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as D

import torchvision
from torchvision import transforms as T




EPOCHES = 20
BATCH_SIZE = 16
# BATCH_SIZE = 32
IMAGE_SIZE = 256
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' 

trfm = A.Compose([
    A.Resize(IMAGE_SIZE, IMAGE_SIZE),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(),
])





class TianChiDataset(D.Dataset):
    def __init__(self, paths, rles, transform, test_mode=False):
        self.paths = paths
        self.rles = rles
        self.transform = transform
        self.test_mode = test_mode
        
        self.len = len(paths)
        self.as_tensor = T.Compose([
            T.ToPILImage(),
            T.Resize(IMAGE_SIZE),
            T.ToTensor(),
            T.Normalize([0.625, 0.448, 0.688],
                        [0.131, 0.177, 0.101]),
        ])
        
    # get data operation
    def __getitem__(self, index):
        img = cv2.imread(self.paths[index])
        if not self.test_mode:
            mask = rle_decode(self.rles[index])
            augments = self.transform(image=img, mask=mask)
            return self.as_tensor(augments['image']), augments['mask'][None]
        else:
            return self.as_tensor(img), ''        
    
    def __len__(self):
        """
        Total number of samples in the dataset
        """
        return self.len
        
        
train_mask = pd.read_csv('./train_mask.csv', sep='\t', names=['name', 'mask'])
train_mask['name'] = train_mask['name'].apply(lambda x: './train/' + x)

img = cv2.imread(train_mask['name'].iloc[0])
mask = rle_decode(train_mask['mask'].iloc[0])

print(rle_encode(mask) == train_mask['mask'].iloc[0])



dataset = TianChiDataset(
    train_mask['name'].values,
    train_mask['mask'].fillna('').values,
    trfm, False
)



image, mask = dataset[0]
plt.figure(figsize=(16,8))
plt.subplot(121)
plt.imshow(mask[0], cmap='gray')
plt.subplot(122)
plt.imshow(image[0]);




valid_idx, train_idx = [], []
for i in range(len(dataset)):
    if i % 7 == 0:
        valid_idx.append(i)
#     else:
    elif i % 7 == 1:
        train_idx.append(i)
        
train_ds = D.Subset(dataset, train_idx)
valid_ds = D.Subset(dataset, valid_idx)

# define training and validation data loaders
loader = D.DataLoader(
    train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)

vloader = D.DataLoader(
    valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    
    
    
 def get_model():
    model = torchvision.models.segmentation.fcn_resnet50(True)
    
#     pth = torch.load("../input/pretrain-coco-weights-pytorch/fcn_resnet50_coco-1167a1af.pth")
#     for key in ["aux_classifier.0.weight", "aux_classifier.1.weight", "aux_classifier.1.bias", "aux_classifier.1.running_mean", "aux_classifier.1.running_var", "aux_classifier.1.num_batches_tracked", "aux_classifier.4.weight", "aux_classifier.4.bias"]:
#         del pth[key]
    
    model.classifier[4] = nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
    return model

@torch.no_grad()
def validation(model, loader, loss_fn):
    losses = []
    model.eval()
    for image, target in loader:
        image, target = image.to(DEVICE), target.float().to(DEVICE)
        output = model(image)['out']
        loss = loss_fn(output, target)
        losses.append(loss.item())
        
    return np.array(losses).mean()
    
    
model = get_model()
model.to(DEVICE);

optimizer = torch.optim.AdamW(model.parameters(),
                  lr=1e-4, weight_decay=1e-3)

class SoftDiceLoss(nn.Module):
    def __init__(self, smooth=1., dims=(-2,-1)):

        super(SoftDiceLoss, self).__init__()
        self.smooth = smooth
        self.dims = dims
    
    def forward(self, x, y):
        tp = (x * y).sum(self.dims)
        fp = (x * (1 - y)).sum(self.dims)
        fn = ((1 - x) * y).sum(self.dims)
        
        dc = (2 * tp + self.smooth) / (2 * tp + fp + fn + self.smooth)
        dc = dc.mean()
        return 1 - dc
    
bce_fn = nn.BCEWithLogitsLoss()
dice_fn = SoftDiceLoss()

def loss_fn(y_pred, y_true):
    bce = bce_fn(y_pred, y_true)
    dice = dice_fn(y_pred.sigmoid(), y_true)
    return 0.8*bce+ 0.2*dice
    
    
    
    
header = r'''
        Train | Valid
Epoch |  Loss |  Loss | Time, m
'''
#          Epoch         metrics            time
raw_line = '{:6d}' + '\u2502{:7.3f}'*2 + '\u2502{:6.2f}'
print(header)

EPOCHES = 5
best_loss = 10
for epoch in range(1, EPOCHES+1):
    losses = []
    start_time = time.time()
    model.train()
    for image, target in tqdm_notebook(loader):
        
        image, target = image.to(DEVICE), target.float().to(DEVICE)
        optimizer.zero_grad()
        output = model(image)['out']
        loss = loss_fn(output, target)
        loss.backward()
        optimizer.step()
        losses.append(loss.item())
        # print(loss.item())
        
    vloss = validation(model, vloader, loss_fn)
    print(raw_line.format(epoch, np.array(losses).mean(), vloss,
                              (time.time()-start_time)/60**1))
    losses = []
    
    if vloss < best_loss:
        best_loss = vloss
        torch.save(model.state_dict(), './model_best.pth')
        
        
trfm = T.Compose([
    T.ToPILImage(),
    T.Resize(IMAGE_SIZE),
    T.ToTensor(),
    T.Normalize([0.625, 0.448, 0.688],
                [0.131, 0.177, 0.101]),
])

subm = []

model.load_state_dict(torch.load("./model_best.pth"))
model.eval()



test_mask = pd.read_csv('./test_a_samplesubmit.csv', sep='\t', names=['name', 'mask'])
test_mask['name'] = test_mask['name'].apply(lambda x: './test_a/' + x)

for idx, name in enumerate(tqdm_notebook(test_mask['name'].iloc[:])):
    image = cv2.imread(name)
    image = trfm(image)
    with torch.no_grad():
        image = image.to(DEVICE)[None]
        score = model(image)['out'][0][0]
        score_sigmoid = score.sigmoid().cpu().numpy()
        score_sigmoid = (score_sigmoid > 0.5).astype(np.uint8)
        score_sigmoid = cv2.resize(score_sigmoid, (512, 512))

        
        # break
    subm.append([name.split('/')[-1], rle_encode(score_sigmoid)])
    
    
    
subm = pd.DataFrame(subm)
subm.to_csv('./tmp.csv', index=None, header=None, sep='\t')


plt.figure(figsize=(16,8))
plt.subplot(121)
plt.imshow(rle_decode(subm[1].fillna('').iloc[0]), cmap='gray')
plt.subplot(122)
plt.imshow(cv2.imread('./test_a/' + subm[0].iloc[0]));

```

##### æ¨¡å‹ç»“æœ

![img](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-%E5%9C%B0%E8%A1%A8%E5%BB%BA%E7%AD%91%E7%89%A9%E8%AF%86%E5%88%AB/9968CA0521CED79554B68EAFBC7B24ED.png)

![image-20210316152506215](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-%E5%9C%B0%E8%A1%A8%E5%BB%BA%E7%AD%91%E7%89%A9%E8%AF%86%E5%88%AB/image-20210316152506215.png)